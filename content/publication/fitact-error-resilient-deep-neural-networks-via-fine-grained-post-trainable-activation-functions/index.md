---
title: "FitAct: Error Resilient Deep Neural Networks via Fine-Grained
  Post-Trainable Activation Functions"
subtitle: sdfsdf
publication_types:
  - "1"
authors:
  - admin
  - Behnam Ghavami
  - Zhenman Fang
  - Lesley Shannon
author_notes:
  - werwer
doi: asdf
publication: Design, Automation & Test in Europe Conference & Exhibition (*DATE*)
publication_short: " DATE (Under Review) "
abstract: In this paper, we propose **FitAct**, a low-cost approach to enhance
  the error resilience of DNNs by deploying fine-grained post-trainable
  activation functions. The main idea is to precisely bound the activation value
  of each individual neuron via neuron-wise bounded activation functions, so
  that it could prevent the fault propagation in the network. To avoid complex
  DNN model re-training, we propose to decouple the accuracy training and
  resilience training, and develop a lightweight post-training phase to learn
  these activation functions with precise bound values. Experimental results on
  widely used DNN models such as AlexNet, VGG16, and ResNet50 demonstrate that
  FitAct outperform state-of-the-art studies such as Clip-Act and Ranger in
  enhancing the DNN error resilience for a wide range of fault rates, while
  adding manageable runtime and memory space overheads.
draft: false
featured: false
tags:
  - a
categories:
  - b
projects:
  - c
slides: d
image:
  filename: ""
  focal_point: ""
  preview_only: false
  caption: ""
  alt_text: sdsdfsdfsdf
summary: h In this paper, we propose **FitAct**, a low-cost approach to enhance
  the error resilience of DNNs by deploying fine-grained post-trainable
  activation functions. The main idea is to precisely bound the activation value
  of each individual neuron via neuron-wise bounded activation functions, so
  that it could prevent the fault propagation in the network. To avoid complex
  DNN model re-training, we propose to decouple the accuracy training and
  resilience training, and develop a lightweight post-training phase to learn
  these activation functions with precise bound values. Experimental results on
  widely used DNN models such as AlexNet, VGG16, and ResNet50 demonstrate that
  FitAct outperform state-of-the-art studies such as Clip-Act and Ranger in
  enhancing the DNN error resilience for a wide range of fault rates, while
  adding manageable runtime and memory space overheads.
date: 2021-10-28T13:02:49.505Z
---
this is ti?